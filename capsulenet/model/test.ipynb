{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros([1,5,5])\n",
    "\n",
    "a = torch.stack([a]*5,dim=0)\n",
    "\n",
    "print a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5,padding=(2,2))\n",
    "        self.conv2 = nn.Conv2d(6,16,5,padding=(2,2))\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(16*7*7,1024)\n",
    "        self.fc2 = nn.Linear(1024,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(F.relu(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(F.relu(x))\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    net = Net()\n",
    "    print net  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes exactly 5 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-1ce41cb90ce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCapsNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes exactly 5 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "class CapsNet(nn.Module):\n",
    "    \"\"\"\n",
    "    input :a group of capsule -> shape:[batch_size*1152(feature_num)*8(in_dim)]\n",
    "    output:a group of new capsule -> shape[batch_size*10(feature_num)*16(out_dim)]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,in_features,out_features,in_dim,out_dim):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(Capsnet,self).__init__()\n",
    "        #number of output features,10\n",
    "        self.out_features = out_features\n",
    "        #number of input features,1152\n",
    "        self.in_features = in_features\n",
    "        #dimension of input capsule\n",
    "        self.in_dim = in_dim\n",
    "        #dimension of output capsule\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        #full connect parameter W with shape [1(batch共享),1152,10,8,16]\n",
    "        self.W = nn.Parameter(torch.randn(1,self.in_features,self.out_features,in_dim,out_dim))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #input x,shape=[batch_size,in_features,in_dim]\n",
    "        #[batch_size,1152,8]\n",
    "        # (batch, input_features, in_dim) -> (batch, in_features, out_features,1,in_dim)\n",
    "        x = torch.stack([x] * self.out_features, dim=2).unsqueeze(3)\n",
    "        # u_hat shape->(batch_size,in_features,out_features,out_dim)=(batch,1152,10,16,1)\n",
    "        u_hat = torch.matmul(self.W,x)\n",
    "        #b for generate weight c,with shape->[1,1152,10,1]\n",
    "        b = torch.zeros([1,self.in_features,self.out_features,1])\n",
    "        for i in range(3):\n",
    "            c = F.softmax(b,dim=2)\n",
    "            #c shape->[batch_size,1152,10,1,1]\n",
    "            c = torch.cat([c] * batch_size, dim=0).unsqueeze(dim=4)\n",
    "            #s shape->[batch_size,1,10,16,1]\n",
    "            s = u_hat * c.sum(dim=1,keep_dim=True)\n",
    "            #output shape->[batch_size,1,10,16,1]\n",
    "            v = squash(s,dim=-2)\n",
    "            v_1 = torch.cat([v] * self.in_features, dim=1)\n",
    "            #(batch,1152,10,1,16)matmul(batch,1152,10,16,1)->(batch,1152,10,1,1)\n",
    "            #squeeze\n",
    "            #mean->(1,1152,10,1)\n",
    "            update_b = torch.matmul(u_hat.transpose(3,4),v_1).squeeze(dim=4).mean(dim=0,keep_dim=True)\n",
    "            b = b+update_b\n",
    "        return v.squeeze(dim=1)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    net = CapsNet()\n",
    "    print net\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CapsConv(nn.Module):\n",
    "    def __init__(self,in_channels=256,out_dim=8):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_dim = out_dim\n",
    "        super(CapsConv,self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
    "                              out_channels=32,  # fixme constant\n",
    "                              kernel_size=9,  # fixme constant\n",
    "                              stride=2, # fixme constant\n",
    "                              bias=True)\n",
    "        \n",
    "    def forward(self,x)\n",
    "        #input x with shape ->[batch_size,in_features,height,width]\n",
    "        #output with shape->[batch_size,32,6,6]\n",
    "        x = [self.conv(x) for i in range(self.out_dim)]\n",
    "        #output with shape->[batch_size,8,32,6,6]\n",
    "        x = torch.stack(x,dim=1)\n",
    "        #return shape->[batch_size,1152,8]\n",
    "        x = squash(x,dim=2)\n",
    "        return x.view(x.size(0),self.out_dim,-1).transpose(1,2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squash(x,dim):\n",
    "    #we should do spuash in each capsule.\n",
    "    #we use dim to select\n",
    "    sum_sq = torch.sum(x**2,dim=dim,keep_dim=True)\n",
    "    sum_sqrt = torch.sqrt(sum_sq)\n",
    "    return (sum_sq/(1.0+sum_sq))* x/sum_sqrt\n",
    "    \n",
    "def loss(labels,v):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        labels:[batch_size,10]\n",
    "        v:[batch_size,10,16,1]\n",
    "    \"\"\"\n",
    "    #shape->[batch_size,10,1,1]\n",
    "    v_norm = torch.sqrt(torch.sum(v**2,dim=2,keep_dim=True)).squeeze()\n",
    "    zero = torch.zeros([1])\n",
    "    m_plus = 0.9\n",
    "    m_minus = 0.1\n",
    "    lamda = 0.5\n",
    "    \n",
    "    #shape->[batch_size,10]\n",
    "    L = torch.max(0,m_plus-v_norm)**2\n",
    "    R = torch.max(0,v_norm-m_minus)**2\n",
    "    #equation 4 in paper\n",
    "    loss = torch.sum(labels*L+(1-labels)*R,dim=1)\n",
    "    #shape->[batch_size,]\n",
    "    loss = loss.mean()\n",
    "    #shape->[1,]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.ones(shape=[1152,1,8])\n",
    "weight = np.ones(shape=[10,1152,8,16])\n",
    "u = np.zeros(shape=[10,1152,1,16])\n",
    "c = np.zeros(shape=[10,1152])\n",
    "s = np.zeros(shape=[10,16])\n",
    "\n",
    "\n",
    "for i in range(weight.shape[0]):\n",
    "    for j in range(a.shape[0]):\n",
    "        u[i][j]=a[i].dot(weight[i][j])\n",
    "    s[i] = np.sum(c[i]*s[i].squeeze(),axis=0)\n",
    "\n",
    "print s.shape\n",
    "\n",
    "\n",
    "\n",
    "def spuashing(s):\n",
    "    return s\n",
    " \n",
    "def dynamic_routing(d,r=3):\n",
    "    b = np.ones(shape=[1152,10])\n",
    "    for iteration in range(r):\n",
    "        #在行上面做softmax，\n",
    "        #(output_dim)\n",
    "        c = F.softmax(b,axis=0)\n",
    "        v = spuashing(s)\n",
    "        b = b+u*v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.3333  0.3333  0.3333  0.3333  0.3333  0.3333  0.3333  0.3333\n",
       " 0.3333  0.3333  0.3333  0.3333  0.3333  0.3333  0.3333  0.3333\n",
       " 0.3333  0.3333  0.3333  0.3333  0.3333  0.3333  0.3333  0.3333\n",
       "[torch.FloatTensor of size 3x8]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(shape=[3,3])\n",
    "b = np.ones(shape=[3,8])\n",
    "\n",
    "print np.matmul(a,b).shape\n",
    "a = torch.Tensor(b)\n",
    "a = Variable(a)\n",
    "F.softmax(a,dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 8, 32, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "a = [torch.zeros([256,32,6,6]) for i in range(8)]\n",
    "\n",
    "b = torch.stack(a,dim=1)\n",
    "print b.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1152, 10, 1, 16])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones([1,1152,10,1,8])\n",
    "\n",
    "b = torch.ones([1,1152,10,8,16])\n",
    "\n",
    "c = torch.matmul(a,b)\n",
    "print c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.5112  0.7516  0.5362  2.7552  0.0000\n",
      " 0.7594  0.0000  0.0000  0.1409  0.3340\n",
      " 0.7613  0.0000  0.1501  0.0000  0.0280\n",
      " 0.0000  0.1042  3.3040  1.0825  0.6528\n",
      "[torch.FloatTensor of size 4x5]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8632503002882004"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn([4,5])\n",
    "b = torch.ones([5,6,5])\n",
    "zero = torch.zeros([1])\n",
    "\n",
    "print torch.max(a,zero)\n",
    "\n",
    "torch.sum(a,dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones([5,5,6])\n",
    "\n",
    "b = a.unsqueeze(dim=3)\n",
    "print b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

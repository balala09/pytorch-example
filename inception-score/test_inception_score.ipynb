{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "im = Image.open('fake_samples_epoch_019.png')\n",
    "image = np.array(im)\n",
    "split_images = np.ones(shape=[64,32,32,3]).astype(image.dtype);\n",
    "index = 0\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        split_images[index,:,:,:] = image[i*34+2:(i+1)*34,j*34+2:(j+1)*34,:]\n",
    "        index = index+1\n",
    "\n",
    "print split_images.shape\n",
    "print image.shape\n",
    "\n",
    "images = split_images.transpose([0,3,1,2])\n",
    "# print split_images[2,:,:,:]\n",
    "print images.shape\n",
    "#split_images(64,32,32,3)\n",
    "\n",
    "# print image[0*66+2:(0+1)*66,2*66+2:(2+1)*66,:]\n",
    "plt.imshow(split_images[0,:,:,:]);\n",
    "plt.show()\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "z = torch.randn(2500,100,1,1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "nz = 100\n",
    "ngf = 64\n",
    "nc = 3\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nz = 100\n",
    "ndf = 64\n",
    "nc = 3\n",
    "batch_size = 2500\n",
    "bn = True\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(nz,ndf*4,4,1,0,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(ndf*4)\n",
    "        #[batch_size,ngf*4,4,4]\n",
    "        self.deconv2 = nn.ConvTranspose2d(ndf*4,ndf*2,4,2,1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(ndf*2)\n",
    "        #[batch_size,ngf*2,8,8]\n",
    "        self.deconv3 = nn.ConvTranspose2d(ndf*2,ndf*1,4,2,1,bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf)\n",
    "        #[batch_size,ngf*1,16,16]\n",
    "        self.deconv4 = nn.ConvTranspose2d(ndf,nc,4,2,1,bias=False)\n",
    "        #[batch_size,3,32,32]\n",
    "    def forward(self,x):\n",
    "        #input x with shape[batch_size,nz,1,1]\n",
    "        x = self.deconv1(x,output_size=[batch_size,ndf*4,4,4])\n",
    "        if bn:\n",
    "            x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv2(x,output_size=[batch_size,ndf*2,8,8])\n",
    "        if bn:\n",
    "            x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv3(x,output_size=[batch_size,ndf*1,16,16])\n",
    "        if bn:\n",
    "            x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv4(x,output_size=[batch_size,nc,32,32])\n",
    "        x = F.tanh(x)\n",
    "        #return [batch_size,nc,32,32]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2500, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "g_net = Generator()\n",
    "g_net.load_state_dict(torch.load(\"gnet_090.pkl\"))\n",
    "g_net = g_net.cuda()\n",
    "images = g_net(z)\n",
    "print images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import inception_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0835, -0.0147, -0.0750,  ...,  0.4951,  0.3799,  0.3156],\n",
      "        [ 0.0191,  0.0234,  0.0581,  ...,  0.1702, -0.3978, -0.2674],\n",
      "        [ 0.0236,  0.0684,  0.1433,  ..., -0.0899, -0.6069, -0.4634],\n",
      "        ...,\n",
      "        [ 0.1467,  0.1416,  0.1313,  ...,  0.2054,  0.1243,  0.1315],\n",
      "        [ 0.1027,  0.1260,  0.1700,  ...,  0.0991,  0.0452,  0.1735],\n",
      "        [ 0.0121,  0.0716,  0.1173,  ...,  0.2275,  0.2631,  0.2751]])\n"
     ]
    }
   ],
   "source": [
    "print images[1,1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lrh/anaconda2/lib/python2.7/site-packages/torch/nn/functional.py:1749: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "inception_score.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x).data.cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.6876891056295182, 0.14061890518570849)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#inception_score(IgnoreLabelDataset(cifar), cuda=True, batch_size=32, resize=True, splits=10)\n",
    "#def inception_score(imgs, cuda=True, batch_size=32, resize=False, splits=1):\n",
    "#   Computes the inception score of the generated images imgs\n",
    "#     imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n",
    "#     cuda -- whether or not to run on GPU\n",
    "#     batch_size -- batch size for feeding into Inception v3\n",
    "#     splits -- number of splits\n",
    "#     \n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from inception_score import inception_score\n",
    "class cifarDataset(data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = images\n",
    "    def __getitem__(self,index):\n",
    "        return self.data[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    dataset = cifarDataset()\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)\n",
    "    print (inception_score(dataset, cuda=True, batch_size=32, resize=True, splits=10))\n",
    "#     for data in dataloader:\n",
    "#         print data.shape\n",
    "#         break\n",
    "    #inception_score.inception_score(dataset,splits=10)\n",
    "    \n",
    "#gnet_050:4.96+0.15\n",
    "#gnet_100:5.14+0.17    \n",
    "#gnet_150:4.97+0.13    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 32, 32])\n",
      "tensor([[[ 0.2078, -0.0118, -0.1765,  ..., -0.2863, -0.3176, -0.3804],\n",
      "         [ 0.0980,  0.1373, -0.0196,  ..., -0.2471, -0.3961, -0.4431],\n",
      "         [ 0.0980,  0.0902, -0.0980,  ..., -0.3804, -0.4667, -0.4745],\n",
      "         ...,\n",
      "         [ 0.3725,  0.2235,  0.2078,  ..., -0.6706, -0.5216, -0.2706],\n",
      "         [ 0.2941,  0.2235,  0.2471,  ..., -0.1922, -0.0353,  0.0275],\n",
      "         [ 0.2784,  0.2392,  0.2784,  ...,  0.1216,  0.1216,  0.1216]],\n",
      "\n",
      "        [[ 0.3882,  0.0745, -0.1843,  ..., -0.2549, -0.2941, -0.3647],\n",
      "         [ 0.2549,  0.2000, -0.0196,  ..., -0.2235, -0.3725, -0.4275],\n",
      "         [ 0.2157,  0.1451, -0.0980,  ..., -0.3569, -0.4510, -0.4588],\n",
      "         ...,\n",
      "         [ 0.3098,  0.2078,  0.2549,  ..., -0.7333, -0.5843, -0.3490],\n",
      "         [ 0.2078,  0.1922,  0.2627,  ..., -0.2706, -0.1059, -0.0510],\n",
      "         [ 0.1608,  0.1608,  0.2235,  ...,  0.0431,  0.0510,  0.0431]],\n",
      "\n",
      "        [[ 0.4667,  0.0667, -0.2549,  ..., -0.4431, -0.4431, -0.4510],\n",
      "         [ 0.3255,  0.2078, -0.0745,  ..., -0.3882, -0.5137, -0.5216],\n",
      "         [ 0.2863,  0.1686, -0.1216,  ..., -0.4980, -0.5686, -0.5686],\n",
      "         ...,\n",
      "         [ 0.3020,  0.2549,  0.3333,  ..., -0.7176, -0.5529, -0.2863],\n",
      "         [ 0.0039,  0.0196,  0.1137,  ..., -0.2471, -0.0588,  0.0275],\n",
      "         [-0.0588, -0.0431,  0.0431,  ...,  0.0902,  0.1137,  0.1294]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "from torchvision.models.inception import inception_v3\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def inception_score(imgs, cuda=True, batch_size=32, resize=False, splits=1):\n",
    "    \"\"\"Computes the inception score of the generated images imgs\n",
    "    imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n",
    "    cuda -- whether or not to run on GPU\n",
    "    batch_size -- batch size for feeding into Inception v3\n",
    "    splits -- number of splits\n",
    "    \"\"\"\n",
    "    N = len(imgs)\n",
    "\n",
    "    assert batch_size > 0\n",
    "    assert N > batch_size\n",
    "\n",
    "    # Set up dtype\n",
    "    if cuda:\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"WARNING: You have a CUDA device, so you should probably set cuda=True\")\n",
    "        dtype = torch.FloatTensor\n",
    "\n",
    "    # Set up dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n",
    "\n",
    "    # Load inception model\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).type(dtype)\n",
    "    inception_model.eval();\n",
    "    up = nn.Upsample(size=(299, 299), mode='bilinear').type(dtype)\n",
    "    def get_pred(x):\n",
    "        if resize:\n",
    "            x = up(x)\n",
    "        x = inception_model(x)\n",
    "        return F.softmax(x).data.cpu().numpy()\n",
    "\n",
    "    # Get predictions\n",
    "    preds = np.zeros((N, 1000))\n",
    "\n",
    "    for i, batch in enumerate(dataloader, 0):\n",
    "        batch = batch.type(dtype)\n",
    "        batchv = Variable(batch)\n",
    "        batch_size_i = batch.size()[0]\n",
    "\n",
    "        preds[i*batch_size:i*batch_size + batch_size_i] = get_pred(batchv)\n",
    "\n",
    "    # Now compute the mean kl-div\n",
    "    split_scores = []\n",
    "\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
    "        py = np.mean(part, axis=0)\n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]\n",
    "            scores.append(entropy(pyx, py))\n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    class IgnoreLabelDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, orig):\n",
    "            self.orig = orig\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return self.orig[index][0]\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.orig)\n",
    "\n",
    "    import torchvision.datasets as dset\n",
    "    import torchvision.transforms as transforms\n",
    "\n",
    "    cifar = dset.CIFAR10(root='/home/lrh/dataset/cifar-10', download=False,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.Resize(32),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                             ])\n",
    "    )\n",
    "\n",
    "    IgnoreLabelDataset(cifar)\n",
    "    dataloader = torch.utils.data.DataLoader(IgnoreLabelDataset(cifar), batch_size=32)\n",
    "    \n",
    "    for data in dataloader:\n",
    "        print data.shape\n",
    "        print data[1]\n",
    "        break\n",
    "    \n",
    "    #print (\"Calculating Inception Score...\")\n",
    "    #print (inception_score(IgnoreLabelDataset(cifar), cuda=True, batch_size=32, resize=True, splits=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "12500\n",
      " bird truck   dog   dog\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f23962deb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Aug 23 14:02:48 2017\n",
    "\n",
    "@author: lrh\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='/mnt/hgfs/ubuntu14/dataset', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='/mnt/hgfs/ubuntu14/dataset', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "print len(trainloader)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "##FloatTensor  [batch_size,channel,height,width]\n",
    "##[4,1,32,32]\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "########################################################################\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='/mnt/hgfs/ubuntu14/dataset', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='/mnt/hgfs/ubuntu14/dataset', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "########################################################################\n",
    "# Let us show some of the training images, for fun.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# 2. Define a Convolution Neural Network\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Copy the neural network from the Neural Networks section before and modify it to\n",
    "# take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "########################################################################\n",
    "# 3. Define a Loss function and optimizer\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Let's use a Classification Cross-Entropy loss and SGD with momentum\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "########################################################################\n",
    "# 4. Train the network\n",
    "# ^^^^^^^^^^^^^^^^^^^^\n",
    "#\n",
    "# This is when things start to get interesting.\n",
    "# We simply have to loop over our data iterator, and feed the inputs to the\n",
    "# network and optimize\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# 5. Test the network on the test data\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#\n",
    "# We have trained the network for 2 passes over the training dataset.\n",
    "# But we need to check if the network has learnt anything at all.\n",
    "#\n",
    "# We will check this by predicting the class label that the neural network\n",
    "# outputs, and checking it against the ground-truth. If the prediction is\n",
    "# correct, we add the sample to the list of correct predictions.\n",
    "#\n",
    "# Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "outputs = net(Variable(images))\n",
    "\n",
    "########################################################################\n",
    "# The outputs are energies for the 10 classes.\n",
    "# Higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class.\n",
    "# So, let's get the index of the highest energy:\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "########################################################################\n",
    "# That looks waaay better than chance, which is 10% accuracy (randomly picking\n",
    "# a class out of 10 classes).\n",
    "# Seems like the network learnt something.\n",
    "#\n",
    "# Hmmm, what are the classes that performed well, and the classes that did\n",
    "# not perform well:\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "input:[batch_size,in_channel,height,width]\n",
    "kernel:[out_channel,in_channel,kh,kw]\n",
    "\"\"\"\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        #(28-5+1)/2=12\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #(12-5+1)/2=4\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        print \"after conv1 size is {}\".format(x.size())\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        print \"after conv2 size is {}\".format(x.size())\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "print \"hello world\"\n",
    "input = Variable(torch.Tensor(np.random.randint(1,10,size=(1,1,32,32))))\n",
    "print net.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "print torch.Tensor([1,2])\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "    \n",
    "net= Net()\n",
    "print net\n",
    "input = Variable(torch.Tensor(1,1,32,32))\n",
    "net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "not torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "learning_rate = 0.009;\n",
    "\n",
    "x = Parameter(torch.Tensor([10]),requires_grad=True);\n",
    "\n",
    "print type(x)\n",
    "def loss_fun(x):\n",
    "    loss = x**2-10*x+50\n",
    "    return loss\n",
    "\n",
    "optimizer = optim.Adam([x], lr = 0.1)\n",
    "#I think it's a much better design choice to keep Variables immutable,\n",
    "#immutable : so it will rebuild a new variable.\n",
    "########################--apaszke\n",
    "for i in range(1000):\n",
    "    l = loss_fun(x)\n",
    "    loss = l**2\n",
    "    \n",
    "    #loss.backward()\n",
    "    \n",
    "    #print x.grad\n",
    "    \n",
    "    ####intermediary variable grad is None.!!!\n",
    "    #print l.grad\n",
    "    \n",
    "    #x.grad.data.fill_(0)\n",
    "    #x.data.sub_(learning_rate*x.grad.data)\n",
    "    #print x\n",
    "    #x.grad = None\n",
    "    #x.grad.data.fill_(0)\n",
    "    #print x\n",
    "    #print \"grad:{}\".format(x.grad)\n",
    "    #print type(x)\n",
    "    #x = Variable((x - learning_rate*x.grad).data,requires_grad=True)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "a = Variable(torch.Tensor([[1,2]]));\n",
    "def f(a):\n",
    "    a[0][1] = 5\n",
    "\n",
    "f(a)\n",
    "print a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def F():\n",
    "    for i in range(5, 9):\n",
    "        for j in range(21, 29):\n",
    "            x = yield i\n",
    "            print x\n",
    "            y = (yield j) * 100\n",
    "            x += y\n",
    "            print '>>>', x\n",
    "\n",
    "gen = F()\n",
    "gen.send(None)\n",
    "#a2 = gen.next()\n",
    "#gen.next()\n",
    "a1 = gen.send(66)\n",
    "a2 = gen.send(77)\n",
    "print a1\n",
    "print a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def consumer():\n",
    "    r = -5\n",
    "    for i in xrange(3):\n",
    "        n = yield r\n",
    "        print n\n",
    "        \n",
    "c = consumer()\n",
    "\n",
    "print \"first run generator:{}\".format(c.next())\n",
    "\n",
    "print \"second run generator:{}\".format(c.next())\n",
    "\n",
    "print c.next()\n",
    "\n",
    "#c.send(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f():\n",
    "    i = 0\n",
    "    for n in xrange(3):\n",
    "        i = yield i\n",
    "        print \"i in function:{}\".format(i)\n",
    "        \n",
    "c = f()\n",
    "print c.next()\n",
    "\n",
    "c.send(10)\n",
    "c.send(20)\n",
    "c.send(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = ''\n",
    "'.' if prefix else \"hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "print(torch.Tensor([1,2]))\n",
    "\n",
    "\n",
    "############################################module\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor([[1,2]]))\n",
    "        self.bias = nn.Parameter(torch.Tensor([[1]]))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = nn.Sigmoid()(self.weight.mm(x)+self.bias)\n",
    "        return x\n",
    "    \n",
    "net= Net()\n",
    "print(net)\n",
    "#input = Variable(torch.Tensor(1,1,32,32))\n",
    "\n",
    "input = Variable(torch.Tensor([[1],[2]]))\n",
    "\n",
    "#for parameter in net.parameters():\n",
    "#    print parameter\n",
    "\n",
    "labels = 1;\n",
    "\n",
    "##############################################loss\n",
    "def loss_fn(labels,logits):\n",
    "    l = labels*torch.log(logits)+(1-labels)*(torch.log(1-logits))\n",
    "    return -l;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################optimizer\n",
    "optimizer = optim.SGD(net.parameters(),lr = 0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "############################################training\n",
    "running_loss = 0.0\n",
    "for i in xrange(1000):\n",
    "    logits = net(input)\n",
    "    loss = loss_fn(labels,logits)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%100 == 0:\n",
    "        print (\"loss is %3f\" %(loss.data[0][0]))\n",
    "        \n",
    "print(net(input).data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.Tensor([[1,2]])\n",
    "b = torch.Tensor([[1],[2]])\n",
    "print a.mm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "w1 = Parameter(torch.Tensor([1]))\n",
    "w2 = Parameter(torch.Tensor([2]))\n",
    "\n",
    "y = w1*2\n",
    "z = w2*y\n",
    "out = z - 5 \n",
    "out.backward()\n",
    "\n",
    "print w2.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

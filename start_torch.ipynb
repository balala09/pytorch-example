{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 8192])\n",
      "Generator(\n",
      "  (preprocess): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=8192, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "DIM = 128\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        preprocess = nn.Sequential(\n",
    "            nn.Linear(128, 4 * 4 * 4 * DIM),\n",
    "            #nn.BatchNorm2d(4 * 4 * 4 * DIM),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.preprocess(input)\n",
    "        return output\n",
    "g_net = Generator()\n",
    "\n",
    "a = torch.randn(128,128)\n",
    "o = g_net(a)\n",
    "print o.size()\n",
    "print g_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -0.3535,   2.3455,   1.2907,   0.2444,   8.9174,   6.5524,\n",
      "           1.7368,   2.0320,   0.0578,   7.1276,   6.7316,  16.7375,\n",
      "           2.8758,   2.5413,  15.6238,  13.6104,   2.1213,  15.7084,\n",
      "           2.5746,   0.6015],\n",
      "        [  3.6208,   0.0118,   2.2653,   0.6678,   0.0923,   0.0042,\n",
      "           1.0773,   0.7272,   0.4371,   0.2527,   1.0014,   3.1075,\n",
      "           4.8948,  -0.4413,   0.2210,   0.4775,   0.1713,  -0.0382,\n",
      "           0.1104,   0.4821],\n",
      "        [  0.3751,   2.1159,   1.8731,  10.6810,   5.3671,   0.3113,\n",
      "          -0.4796,   8.6201,  15.2288,   2.6877,   0.1063,   3.0320,\n",
      "           1.1585,   7.4914,  -0.0328,   5.6347,   0.7034,  -0.4754,\n",
      "           2.1775,   2.9781],\n",
      "        [ 11.0657,   5.2768,   0.3777,   0.1141,   4.0796,   4.3770,\n",
      "          14.8633,   6.9043,   2.6455,   3.8721,   5.0919,   7.0552,\n",
      "          12.8856,  -0.7220,   1.7092,   3.4297,   1.7244,  12.3890,\n",
      "          -0.5136,   1.7236],\n",
      "        [ -0.0095,  -0.3810,   2.4251,  11.8181,   2.6014,   0.0140,\n",
      "           0.9531,  -1.3486,   0.0828,  10.2654,   0.3766,  -0.2177,\n",
      "           1.1946,   6.4194,   0.0635,   1.7519,  -1.1469,   0.7827,\n",
      "           6.9662,  12.1977],\n",
      "        [  0.8468,  -0.1266,   0.7508,   0.1513,   8.6354,   3.5904,\n",
      "          -1.2280,   6.3883,   2.7819,  -0.1064,   5.3778,   0.5041,\n",
      "          14.4336,   5.4299,   6.4375,   1.0893,  -1.0095,   1.7904,\n",
      "          -0.0812,  23.4404],\n",
      "        [  2.1924,  -0.7045,   0.9391,   0.5355,  11.4362,  -0.0068,\n",
      "          22.8987,  12.2257,  -0.0115,   2.8877,  -0.0142,   4.2898,\n",
      "           0.2359,   6.5904,   0.9772,   7.4829,  -1.3654,   0.7593,\n",
      "           2.1176,   3.5710],\n",
      "        [  1.1230,   0.0227,   7.7672,   0.1887,   6.5468,   6.6019,\n",
      "           9.7501,   2.2823,   3.0580,  -0.3142,   0.1776,  -0.1896,\n",
      "          -0.0344,   0.1439,   0.0555,  -0.2836,   4.9584,   0.8491,\n",
      "          -0.1094,   1.5741],\n",
      "        [ -0.1081,   7.1705,  10.1850,  -0.0146,   4.2028,   3.3204,\n",
      "           6.0039,   0.6907,  -0.0436,   1.3985,   2.6424,   0.0993,\n",
      "           5.5242,   0.5911,  -0.8200,  12.1543,   1.4967,   0.3433,\n",
      "          -0.0439,   0.4488],\n",
      "        [  0.2585,   3.0312,  -0.2119,   1.9705,  22.3991,   0.5209,\n",
      "           9.0396,  10.2570,   0.0623,   8.0820,  -0.6187,   0.1556,\n",
      "           0.2745,  10.0117,   0.1157,   0.5642,   4.8420,   0.1671,\n",
      "          -0.3213,  16.1766]])\n",
      "tensor(54.0164)\n",
      "tensor(13.3943)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "def cov_function(x):\n",
    "    batch_size = x.size()[0]\n",
    "    a = x - x.mean(dim=0,keepdim=True)\n",
    "    cov_matrix = torch.matmul(a.t(),a)/(batch_size-1)\n",
    "    return cov_matrix\n",
    "\n",
    "gradients = torch.randn([10,20])\n",
    "ma_distance = torch.mul(torch.matmul(gradients,cov_function(gradients)),gradients)\n",
    "ma = ((torch.sqrt(torch.sum(ma_distance,dim=1)) - 1) ** 2).mean()\n",
    "print ma_distance\n",
    "print ma\n",
    "\n",
    "print ((gradients.norm(2, dim=1) - 1) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04850119  0.04305651  0.11043543  0.0373755   0.10895795  0.13009706\n",
      "  0.11646731  0.03329951  0.05712657  0.06839128]\n",
      "tensor([ 0.0485,  0.0431,  0.1104,  0.0374,  0.1090,  0.1301,  0.1165,\n",
      "         0.0333,  0.0571,  0.0684])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "def var_function(x):\n",
    "    a = x - x.mean(dim=0,keepdim=True)\n",
    "    #var_matrix = a.norm(2,dim=0)/5\n",
    "    var_matrix = torch.sum(a ** 2,dim=0)/5\n",
    "    return var_matrix\n",
    "\n",
    "x = torch.rand(5,10)\n",
    "x_numpy = x.numpy()\n",
    "\n",
    "print np.var(x_numpy,axis=0)\n",
    "varx = var_function(x)\n",
    "# print x\n",
    "print varx\n",
    "# print x / var\n",
    "\n",
    "#print x.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.80666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(11.709999999999999)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  8.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "a = torch.Tensor([[1,2]])\n",
    "c = torch.ones(2,2)\n",
    "b = torch.Tensor([[3,4]])\n",
    "torch.mul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Aug 23 14:02:48 2017\n",
    "\n",
    "@author: lrh\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='/mnt/hgfs/ubuntu14/dataset', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='/mnt/hgfs/ubuntu14/dataset', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "print len(trainloader)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "##FloatTensor  [batch_size,channel,height,width]\n",
    "##[4,1,32,32]\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "########################################################################\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='/mnt/hgfs/ubuntu14/dataset', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='/mnt/hgfs/ubuntu14/dataset', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "########################################################################\n",
    "# Let us show some of the training images, for fun.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# 2. Define a Convolution Neural Network\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Copy the neural network from the Neural Networks section before and modify it to\n",
    "# take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "########################################################################\n",
    "# 3. Define a Loss function and optimizer\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Let's use a Classification Cross-Entropy loss and SGD with momentum\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "########################################################################\n",
    "# 4. Train the network\n",
    "# ^^^^^^^^^^^^^^^^^^^^\n",
    "#\n",
    "# This is when things start to get interesting.\n",
    "# We simply have to loop over our data iterator, and feed the inputs to the\n",
    "# network and optimize\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# 5. Test the network on the test data\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#\n",
    "# We have trained the network for 2 passes over the training dataset.\n",
    "# But we need to check if the network has learnt anything at all.\n",
    "#\n",
    "# We will check this by predicting the class label that the neural network\n",
    "# outputs, and checking it against the ground-truth. If the prediction is\n",
    "# correct, we add the sample to the list of correct predictions.\n",
    "#\n",
    "# Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "outputs = net(Variable(images))\n",
    "\n",
    "########################################################################\n",
    "# The outputs are energies for the 10 classes.\n",
    "# Higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class.\n",
    "# So, let's get the index of the highest energy:\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "########################################################################\n",
    "# That looks waaay better than chance, which is 10% accuracy (randomly picking\n",
    "# a class out of 10 classes).\n",
    "# Seems like the network learnt something.\n",
    "#\n",
    "# Hmmm, what are the classes that performed well, and the classes that did\n",
    "# not perform well:\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "input:[batch_size,in_channel,height,width]\n",
    "kernel:[out_channel,in_channel,kh,kw]\n",
    "\"\"\"\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        #(28-5+1)/2=12\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #(12-5+1)/2=4\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        print \"after conv1 size is {}\".format(x.size())\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        print \"after conv2 size is {}\".format(x.size())\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "print \"hello world\"\n",
    "input = Variable(torch.Tensor(np.random.randint(1,10,size=(1,1,32,32))))\n",
    "print net.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "print torch.Tensor([1,2])\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "    \n",
    "net= Net()\n",
    "print net\n",
    "input = Variable(torch.Tensor(1,1,32,32))\n",
    "net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "not torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([ 5.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "learning_rate = 0.009;\n",
    "one = torch.FloatTensor([1]);\n",
    "\n",
    "x = Parameter(torch.Tensor([10]),requires_grad=True);\n",
    "\n",
    "print type(x)\n",
    "def loss_fun(x):\n",
    "    loss = x**2-10*x+50\n",
    "    return loss\n",
    "\n",
    "optimizer = optim.Adam([x], lr = 0.1)\n",
    "#I think it's a much better design choice to keep Variables immutable,\n",
    "#immutable : so it will rebuild a new variable.\n",
    "########################--apaszke\n",
    "for i in range(1000):\n",
    "    l = loss_fun(x)\n",
    "    loss = l**2\n",
    "    \n",
    "    #loss.backward()\n",
    "    \n",
    "    #print x.grad\n",
    "    \n",
    "    ####intermediary variable grad is None.!!!\n",
    "    #print l.grad\n",
    "    \n",
    "    #x.grad.data.fill_(0)\n",
    "    #x.data.sub_(learning_rate*x.grad.data)\n",
    "    #print x\n",
    "    #x.grad = None\n",
    "    #x.grad.data.fill_(0)\n",
    "    #print x\n",
    "    #print \"grad:{}\".format(x.grad)\n",
    "    #print type(x)\n",
    "    #x = Variable((x - learning_rate*x.grad).data,requires_grad=True)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(one)\n",
    "    #print x.grad\n",
    "    optimizer.step()\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  5.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = Variable(torch.Tensor([[1,2]]));\n",
    "def f(a):\n",
    "    a[0][1] = 5\n",
    "\n",
    "f(a)\n",
    "print a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def F():\n",
    "    for i in range(5, 9):\n",
    "        for j in range(21, 29):\n",
    "            x = yield i\n",
    "            print x\n",
    "            y = (yield j) * 100\n",
    "            x += y\n",
    "            print '>>>', x\n",
    "\n",
    "gen = F()\n",
    "gen.send(None)\n",
    "#a2 = gen.next()\n",
    "#gen.next()\n",
    "a1 = gen.send(66)\n",
    "a2 = gen.send(77)\n",
    "print a1\n",
    "print a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def consumer():\n",
    "    r = -5\n",
    "    for i in xrange(3):\n",
    "        n = yield r\n",
    "        print n\n",
    "        \n",
    "c = consumer()\n",
    "\n",
    "print \"first run generator:{}\".format(c.next())\n",
    "\n",
    "print \"second run generator:{}\".format(c.next())\n",
    "\n",
    "print c.next()\n",
    "\n",
    "#c.send(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f():\n",
    "    i = 0\n",
    "    for n in xrange(3):\n",
    "        i = yield i\n",
    "        print \"i in function:{}\".format(i)\n",
    "        \n",
    "c = f()\n",
    "print c.next()\n",
    "\n",
    "c.send(10)\n",
    "c.send(20)\n",
    "c.send(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = ''\n",
    "'.' if prefix else \"hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "print(torch.Tensor([1,2]))\n",
    "\n",
    "\n",
    "############################################module\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor([[1,2]]))\n",
    "        self.bias = nn.Parameter(torch.Tensor([[1]]))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = nn.Sigmoid()(self.weight.mm(x)+self.bias)\n",
    "        return x\n",
    "    \n",
    "net= Net()\n",
    "print(net)\n",
    "#input = Variable(torch.Tensor(1,1,32,32))\n",
    "\n",
    "input = Variable(torch.Tensor([[1],[2]]))\n",
    "\n",
    "#for parameter in net.parameters():\n",
    "#    print parameter\n",
    "\n",
    "labels = 1;\n",
    "\n",
    "##############################################loss\n",
    "def loss_fn(labels,logits):\n",
    "    l = labels*torch.log(logits)+(1-labels)*(torch.log(1-logits))\n",
    "    return -l;\n",
    "\n",
    "def calc_gradient_penalty(nets,input):\n",
    "    \n",
    "    output = nets(input)\n",
    "    \n",
    "    #output gradient w.r.t input\n",
    "    gradients = autograd.grad(outputs=output,inputs=input,grad_output=torch.ones(output.size()).cuda()...\n",
    "                             ,create_graph=True);\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
    "    return gradient_penalty\n",
    "\n",
    "\n",
    "###############################################optimizer\n",
    "optimizer = optim.SGD(net.parameters(),lr = 0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "############################################training\n",
    "running_loss = 0.0\n",
    "for i in xrange(1000):\n",
    "    logits = net(input)\n",
    "    loss = loss_fn(labels,logits)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%100 == 0:\n",
    "        print (\"loss is %3f\" %(loss.data[0][0]))\n",
    "        \n",
    "print(net(input).data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils\n",
    "\n",
    "vutils.save_image(tensor, filename, nrow=8, padding=2, normalize=False, range=None, scale_each=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.Tensor([[1,2]])\n",
    "b = torch.Tensor([[1],[2]])\n",
    "print a.mm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "w1 = Parameter(torch.Tensor([1]))\n",
    "w2 = Parameter(torch.Tensor([2]))\n",
    "\n",
    "y = w1*2\n",
    "z = w2*y\n",
    "out = z - 5 \n",
    "out.backward()\n",
    "\n",
    "print w2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "torch.float32\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "########################################################################\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='/home/lrh/dataset/cifar-10', train=True,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='/home/lrh/dataset/cifar-10', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for data in trainloader:\n",
    "    # get the inputs\n",
    "    inputs, labels = data\n",
    "    # wrap them in Variable\n",
    "    #inputs, labels = Variable(inputs), Variable(labels)\n",
    "    #print \"epoch:{}\".format(epoch)\n",
    "    #print \"hello world\"\n",
    "    #inputs.detach()\n",
    "    #vutils.save_image(tensor, filename, nrow=8, padding=2, normalize=False, range=None, scale_each=False)\n",
    "    #vutils.save_image(inputs.detach(),\"/home/lrh/grad.png\")\n",
    "    print inputs.dtype\n",
    "    print \"hello world\"\n",
    "    break;\n",
    "# print len(trainset)\n",
    "# print len(trainloader)      \n",
    "# print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1752, -1.5280,  0.6509, -1.7830,  1.8385, -0.0505],\n",
      "        [-0.1228, -0.0296,  0.4392, -0.5162, -0.5798,  0.7303],\n",
      "        [ 2.6481, -0.5530,  0.1746, -0.3985, -1.4671, -0.3484],\n",
      "        [ 0.3460,  0.1180,  1.4852, -3.0469,  0.5785, -0.9331],\n",
      "        [-1.4799,  1.7249, -0.4556,  0.0489,  0.5067, -1.2517]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1752, -1.5280,  0.6509, -1.7830,  1.8385, -0.0505],\n",
       "        [-0.1228, -0.0296,  0.4392, -0.5162, -0.5798,  0.7303],\n",
       "        [ 2.6481, -0.5530,  0.1746, -0.3985, -1.4671, -0.3484],\n",
       "        [ 0.3460,  0.1180,  1.4852, -3.0469,  0.5785, -0.9331],\n",
       "        [-1.4799,  1.7249, -0.4556,  0.0489,  0.5067, -1.2517]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "a = torch.randn([5,6])\n",
    "print a\n",
    "a.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "from torch.autograd import Variable\n",
    "\n",
    "a = torch.Tensor([1,2,3,4,5])\n",
    "v_a = Variable(a)\n",
    "\n",
    "a[1:2].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def dense_to_one_hot(labels,class_num):\n",
    "    height = labels.shape[0]\n",
    "    a = np.zeros(shape=[height,class_num])\n",
    "    a[np.arange(height),labels.squeeze()] = 1\n",
    "    return a\n",
    "    \n",
    "labels = np.array([[1],[2],[3]])\n",
    "labels = dense_to_one_hot(labels,10)\n",
    "print labels\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.Tensor([[2,1,1],[3,4,3]])\n",
    "print a\n",
    "a,pos = a.max(dim=1)\n",
    "print a\n",
    "print pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def squash(x,dim):\n",
    "    #we should do spuash in each capsule.\n",
    "    #we use dim to select\n",
    "    sum_sq = torch.sum(x**2,dim=dim,keepdim=True)\n",
    "    print sum_sq\n",
    "    sum_sqrt = torch.sqrt(sum_sq)\n",
    "    return (sum_sq/(1.0+sum_sq))* x/sum_sqrt\n",
    "    \n",
    "\n",
    "a = torch.Tensor([[1,20,20],[4,5,6]])\n",
    "b = squash(a,dim=1)\n",
    "print b\n",
    "print torch.mean(b**2,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.zeros_like([4,1152,8])\n",
    "x = torch.stack([x] * 10, dim=2).unsqueeze(3)\n",
    "print x.shape\n",
    "\n",
    "zero = torch.zeros([1]).double()\n",
    "print zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.Tensor([[4,2],[-4,-2]])\n",
    "zero = torch.zeros([1])\n",
    "x.cuda()\n",
    "print torch.max(zero,x)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def dense_to_one_hot(labels,class_num):\n",
    "    \n",
    "    height = labels.shape[0]\n",
    "    a = np.zeros(shape=[height,class_num])\n",
    "    a[np.arange(height),labels] = 1\n",
    "    return a\n",
    "\n",
    "labels = np.array([5,6,7])\n",
    "labels = dense_to_one_hot(labels,10)\n",
    "print labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

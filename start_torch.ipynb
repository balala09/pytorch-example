{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        w = torch.ones(6,1,5,5).cuda()\n",
    "        x = F.conv2d(x,w)\n",
    "        x = F.max_pool2d(F.relu(x), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "x = torch.ones(64,1,32,32).cuda();\n",
    "net = Net()\n",
    "for i in range(10000):\n",
    "    net(x)\n",
    "    print i;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim_loss(x):\n",
    "    #x with shape [batch_size,num_features]\n",
    "    #ssim_layer = ssim.SSIM(reshape = True,size_average=False,window_size = 11)\n",
    "    delta = 0.01\n",
    "    ssim_l = torch.Tensor(x.shape);\n",
    "    num_feas = ssim_l.size(1)\n",
    "    x_delta = x.clone();\n",
    "    for i in range(num_feas):\n",
    "        x_delta[:,i] = x_delta[:,i]+delta;\n",
    "        \n",
    "        ssim_l_i =torch.ones(64)\n",
    "        #print ssim_l_i.mean()\n",
    "        ssim_l[:,i] = ssim_l_i;\n",
    "        \n",
    "        x_delta[:,i] = x_delta[:,i]-delta;\n",
    "        print i\n",
    "    #with shape[batch_size,num_features]\n",
    "    return ssim_l\n",
    "\n",
    "x = torch.ones(64,32*32*3).cuda()\n",
    "ssim_loss(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "DIM = 128\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        preprocess = nn.Sequential(\n",
    "            nn.Linear(128, 4 * 4 * 4 * DIM),\n",
    "            #nn.BatchNorm2d(4 * 4 * 4 * DIM),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.preprocess(input)\n",
    "        return output\n",
    "g_net = Generator()\n",
    "\n",
    "a = torch.randn(128,128)\n",
    "o = g_net(a)\n",
    "print o.size()\n",
    "print g_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "def cov_function(x):\n",
    "    batch_size = x.size()[0]\n",
    "    a = x - x.mean(dim=0,keepdim=True)\n",
    "    cov_matrix = torch.matmul(a.t(),a)/(batch_size-1)\n",
    "    return cov_matrix\n",
    "\n",
    "gradients = torch.randn([10,20])\n",
    "ma_distance = torch.mul(torch.matmul(gradients,cov_function(gradients)),gradients)\n",
    "ma = ((torch.sqrt(torch.sum(ma_distance,dim=1)) - 1) ** 2).mean()\n",
    "print ma_distance\n",
    "print ma\n",
    "\n",
    "print ((gradients.norm(2, dim=1) - 1) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "def var_function(x):\n",
    "    a = x - x.mean(dim=0,keepdim=True)\n",
    "    #var_matrix = a.norm(2,dim=0)/5\n",
    "    var_matrix = torch.sum(a ** 2,dim=0)/5\n",
    "    return var_matrix\n",
    "\n",
    "x = torch.rand(5,10)\n",
    "x_numpy = x.numpy()\n",
    "\n",
    "print np.var(x_numpy,axis=0)\n",
    "varx = var_function(x)\n",
    "# print x\n",
    "print varx\n",
    "# print x / var\n",
    "\n",
    "#print x.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "a = torch.Tensor([[1,2]])\n",
    "c = torch.ones(2,2)\n",
    "b = torch.Tensor([[3,4]])\n",
    "torch.mul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Aug 23 14:02:48 2017\n",
    "\n",
    "@author: lrh\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='/mnt/hgfs/ubuntu14/dataset', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='/mnt/hgfs/ubuntu14/dataset', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "print len(trainloader)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "##FloatTensor  [batch_size,channel,height,width]\n",
    "##[4,1,32,32]\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "########################################################################\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='/mnt/hgfs/ubuntu14/dataset', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='/mnt/hgfs/ubuntu14/dataset', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "########################################################################\n",
    "# Let us show some of the training images, for fun.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# 2. Define a Convolution Neural Network\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Copy the neural network from the Neural Networks section before and modify it to\n",
    "# take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "########################################################################\n",
    "# 3. Define a Loss function and optimizer\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Let's use a Classification Cross-Entropy loss and SGD with momentum\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "########################################################################\n",
    "# 4. Train the network\n",
    "# ^^^^^^^^^^^^^^^^^^^^\n",
    "#\n",
    "# This is when things start to get interesting.\n",
    "# We simply have to loop over our data iterator, and feed the inputs to the\n",
    "# network and optimize\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# 5. Test the network on the test data\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#\n",
    "# We have trained the network for 2 passes over the training dataset.\n",
    "# But we need to check if the network has learnt anything at all.\n",
    "#\n",
    "# We will check this by predicting the class label that the neural network\n",
    "# outputs, and checking it against the ground-truth. If the prediction is\n",
    "# correct, we add the sample to the list of correct predictions.\n",
    "#\n",
    "# Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "outputs = net(Variable(images))\n",
    "\n",
    "########################################################################\n",
    "# The outputs are energies for the 10 classes.\n",
    "# Higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class.\n",
    "# So, let's get the index of the highest energy:\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "########################################################################\n",
    "# That looks waaay better than chance, which is 10% accuracy (randomly picking\n",
    "# a class out of 10 classes).\n",
    "# Seems like the network learnt something.\n",
    "#\n",
    "# Hmmm, what are the classes that performed well, and the classes that did\n",
    "# not perform well:\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "input:[batch_size,in_channel,height,width]\n",
    "kernel:[out_channel,in_channel,kh,kw]\n",
    "\"\"\"\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        #(28-5+1)/2=12\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #(12-5+1)/2=4\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        print \"after conv1 size is {}\".format(x.size())\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        print \"after conv2 size is {}\".format(x.size())\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "print \"hello world\"\n",
    "input = Variable(torch.Tensor(np.random.randint(1,10,size=(1,1,32,32))))\n",
    "print net.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "print torch.Tensor([1,2])\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "    \n",
    "net= Net()\n",
    "print net\n",
    "input = Variable(torch.Tensor(1,1,32,32))\n",
    "net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "not torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "learning_rate = 0.009;\n",
    "one = torch.FloatTensor([1]);\n",
    "\n",
    "x = Parameter(torch.Tensor([10]),requires_grad=True);\n",
    "\n",
    "print type(x)\n",
    "def loss_fun(x):\n",
    "    loss = x**2-10*x+50\n",
    "    return loss\n",
    "\n",
    "optimizer = optim.Adam([x], lr = 0.1)\n",
    "#I think it's a much better design choice to keep Variables immutable,\n",
    "#immutable : so it will rebuild a new variable.\n",
    "########################--apaszke\n",
    "for i in range(1000):\n",
    "    l = loss_fun(x)\n",
    "    loss = l**2\n",
    "    \n",
    "    #loss.backward()\n",
    "    \n",
    "    #print x.grad\n",
    "    \n",
    "    ####intermediary variable grad is None.!!!\n",
    "    #print l.grad\n",
    "    \n",
    "    #x.grad.data.fill_(0)\n",
    "    #x.data.sub_(learning_rate*x.grad.data)\n",
    "    #print x\n",
    "    #x.grad = None\n",
    "    #x.grad.data.fill_(0)\n",
    "    #print x\n",
    "    #print \"grad:{}\".format(x.grad)\n",
    "    #print type(x)\n",
    "    #x = Variable((x - learning_rate*x.grad).data,requires_grad=True)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(one)\n",
    "    #print x.grad\n",
    "    optimizer.step()\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = Variable(torch.Tensor([[1,2]]));\n",
    "def f(a):\n",
    "    a[0][1] = 5\n",
    "\n",
    "f(a)\n",
    "print a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def F():\n",
    "    for i in range(5, 9):\n",
    "        for j in range(21, 29):\n",
    "            x = yield i\n",
    "            print x\n",
    "            y = (yield j) * 100\n",
    "            x += y\n",
    "            print '>>>', x\n",
    "\n",
    "gen = F()\n",
    "gen.send(None)\n",
    "#a2 = gen.next()\n",
    "#gen.next()\n",
    "a1 = gen.send(66)\n",
    "a2 = gen.send(77)\n",
    "print a1\n",
    "print a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def consumer():\n",
    "    r = -5\n",
    "    for i in xrange(3):\n",
    "        n = yield r\n",
    "        print n\n",
    "        \n",
    "c = consumer()\n",
    "\n",
    "print \"first run generator:{}\".format(c.next())\n",
    "\n",
    "print \"second run generator:{}\".format(c.next())\n",
    "\n",
    "print c.next()\n",
    "\n",
    "#c.send(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f():\n",
    "    i = 0\n",
    "    for n in xrange(3):\n",
    "        i = yield i\n",
    "        print \"i in function:{}\".format(i)\n",
    "        \n",
    "c = f()\n",
    "print c.next()\n",
    "\n",
    "c.send(10)\n",
    "c.send(20)\n",
    "c.send(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = ''\n",
    "'.' if prefix else \"hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "print(torch.Tensor([1,2]))\n",
    "\n",
    "\n",
    "############################################module\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor([[1,2]]))\n",
    "        self.bias = nn.Parameter(torch.Tensor([[1]]))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = nn.Sigmoid()(self.weight.mm(x)+self.bias)\n",
    "        return x\n",
    "    \n",
    "net= Net()\n",
    "print(net)\n",
    "#input = Variable(torch.Tensor(1,1,32,32))\n",
    "\n",
    "input = Variable(torch.Tensor([[1],[2]]))\n",
    "\n",
    "#for parameter in net.parameters():\n",
    "#    print parameter\n",
    "\n",
    "labels = 1;\n",
    "\n",
    "##############################################loss\n",
    "def loss_fn(labels,logits):\n",
    "    l = labels*torch.log(logits)+(1-labels)*(torch.log(1-logits))\n",
    "    return -l;\n",
    "\n",
    "def calc_gradient_penalty(nets,input):\n",
    "    \n",
    "    output = nets(input)\n",
    "    \n",
    "    #output gradient w.r.t input\n",
    "    gradients = autograd.grad(outputs=output,inputs=input,grad_output=torch.ones(output.size()).cuda()...\n",
    "                             ,create_graph=True);\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
    "    return gradient_penalty\n",
    "\n",
    "\n",
    "###############################################optimizer\n",
    "optimizer = optim.SGD(net.parameters(),lr = 0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "############################################training\n",
    "running_loss = 0.0\n",
    "for i in xrange(1000):\n",
    "    logits = net(input)\n",
    "    loss = loss_fn(labels,logits)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%100 == 0:\n",
    "        print (\"loss is %3f\" %(loss.data[0][0]))\n",
    "        \n",
    "print(net(input).data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils\n",
    "\n",
    "vutils.save_image(tensor, filename, nrow=8, padding=2, normalize=False, range=None, scale_each=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.Tensor([[1,2]])\n",
    "b = torch.Tensor([[1],[2]])\n",
    "print a.mm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "w1 = Parameter(torch.Tensor([1]))\n",
    "w2 = Parameter(torch.Tensor([2]))\n",
    "\n",
    "y = w1*2\n",
    "z = w2*y\n",
    "out = z - 5 \n",
    "out.backward()\n",
    "\n",
    "print w2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "########################################################################\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='/home/lrh/dataset/cifar-10', train=True,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='/home/lrh/dataset/cifar-10', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for data in trainloader:\n",
    "    # get the inputs\n",
    "    inputs, labels = data\n",
    "    # wrap them in Variable\n",
    "    #inputs, labels = Variable(inputs), Variable(labels)\n",
    "    #print \"epoch:{}\".format(epoch)\n",
    "    #print \"hello world\"\n",
    "    #inputs.detach()\n",
    "    #vutils.save_image(tensor, filename, nrow=8, padding=2, normalize=False, range=None, scale_each=False)\n",
    "    #vutils.save_image(inputs.detach(),\"/home/lrh/grad.png\")\n",
    "    print inputs.dtype\n",
    "    print \"hello world\"\n",
    "    break;\n",
    "# print len(trainset)\n",
    "# print len(trainloader)      \n",
    "# print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "a = torch.randn([5,6])\n",
    "print a\n",
    "a.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "from torch.autograd import Variable\n",
    "\n",
    "a = torch.Tensor([1,2,3,4,5])\n",
    "v_a = Variable(a)\n",
    "\n",
    "a[1:2].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def dense_to_one_hot(labels,class_num):\n",
    "    height = labels.shape[0]\n",
    "    a = np.zeros(shape=[height,class_num])\n",
    "    a[np.arange(height),labels.squeeze()] = 1\n",
    "    return a\n",
    "    \n",
    "labels = np.array([[1],[2],[3]])\n",
    "labels = dense_to_one_hot(labels,10)\n",
    "print labels\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.Tensor([[2,1,1],[3,4,3]])\n",
    "print a\n",
    "a,pos = a.max(dim=1)\n",
    "print a\n",
    "print pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def squash(x,dim):\n",
    "    #we should do spuash in each capsule.\n",
    "    #we use dim to select\n",
    "    sum_sq = torch.sum(x**2,dim=dim,keepdim=True)\n",
    "    print sum_sq\n",
    "    sum_sqrt = torch.sqrt(sum_sq)\n",
    "    return (sum_sq/(1.0+sum_sq))* x/sum_sqrt\n",
    "    \n",
    "\n",
    "a = torch.Tensor([[1,20,20],[4,5,6]])\n",
    "b = squash(a,dim=1)\n",
    "print b\n",
    "print torch.mean(b**2,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.zeros_like([4,1152,8])\n",
    "x = torch.stack([x] * 10, dim=2).unsqueeze(3)\n",
    "print x.shape\n",
    "\n",
    "zero = torch.zeros([1]).double()\n",
    "print zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.Tensor([[4,2],[-4,-2]])\n",
    "zero = torch.zeros([1])\n",
    "x.cuda()\n",
    "print torch.max(zero,x)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def dense_to_one_hot(labels,class_num):\n",
    "    \n",
    "    height = labels.shape[0]\n",
    "    a = np.zeros(shape=[height,class_num])\n",
    "    a[np.arange(height),labels] = 1\n",
    "    return a\n",
    "\n",
    "labels = np.array([5,6,7])\n",
    "labels = dense_to_one_hot(labels,10)\n",
    "print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.9648e-05,  1.4163e-03,  5.4473e-05,  2.8602e-04,  2.1613e-02,\n",
      "          5.4275e-04,  8.7522e-06,  2.2030e-02,  1.1516e-02,  9.4250e-01],\n",
      "        [ 1.3895e-05,  9.9835e-01,  1.7850e-04,  5.2711e-05,  8.3725e-04,\n",
      "          3.1201e-06,  1.8867e-04,  2.2544e-04,  1.3708e-04,  8.6281e-06],\n",
      "        [ 3.2763e-03,  1.7253e-03,  6.1538e-01,  4.9966e-03,  9.7277e-05,\n",
      "          2.8367e-05,  2.1504e-05,  3.5531e-01,  9.5612e-03,  9.6103e-03],\n",
      "        [ 6.5695e-05,  4.2320e-07,  8.1510e-05,  1.1792e-05,  1.0927e-03,\n",
      "          8.4285e-06,  2.9287e-07,  2.8563e-02,  7.1859e-05,  9.7010e-01],\n",
      "        [ 1.2230e-05,  1.1033e-06,  2.8461e-03,  9.9654e-01,  1.6540e-11,\n",
      "          9.0017e-05,  4.7520e-10,  4.3122e-04,  7.4502e-05,  6.8967e-06],\n",
      "        [ 9.9589e-01,  4.4169e-07,  2.1042e-03,  3.0515e-04,  7.9895e-08,\n",
      "          7.0174e-04,  2.2959e-04,  6.1019e-04,  1.3459e-04,  2.8328e-05],\n",
      "        [ 1.0339e-06,  2.5104e-06,  1.5158e-03,  9.6219e-01,  6.0184e-07,\n",
      "          3.0654e-02,  8.1808e-06,  3.3101e-06,  5.5707e-03,  5.6800e-05],\n",
      "        [ 6.6292e-05,  8.8238e-04,  9.9541e-01,  3.1589e-03,  8.2357e-10,\n",
      "          5.7121e-08,  2.5866e-07,  8.6491e-05,  3.9711e-04,  1.2111e-07],\n",
      "        [ 6.6970e-08,  1.3292e-09,  3.3977e-08,  8.7012e-04,  1.1123e-09,\n",
      "          9.9721e-01,  2.1603e-07,  6.1452e-08,  1.8976e-03,  1.9733e-05],\n",
      "        [ 3.5660e-07,  1.3407e-04,  1.3610e-05,  2.7266e-05,  9.8334e-01,\n",
      "          5.2591e-06,  3.7746e-06,  3.2623e-04,  1.3359e-05,  1.6133e-02],\n",
      "        [ 1.2257e-04,  1.0829e-04,  1.4376e-04,  6.6252e-03,  1.5275e-06,\n",
      "          4.5661e-04,  3.4490e-08,  9.8549e-01,  1.0981e-04,  6.9387e-03],\n",
      "        [ 8.6688e-04,  2.0941e-05,  1.3835e-03,  1.6245e-03,  1.2619e-04,\n",
      "          7.8561e-02,  1.0866e-02,  1.1315e-05,  9.0360e-01,  2.9383e-03],\n",
      "        [ 3.0335e-06,  7.2164e-07,  2.4478e-02,  9.7389e-01,  3.4970e-09,\n",
      "          1.1538e-03,  3.3092e-07,  8.4010e-06,  4.6078e-04,  2.9417e-06],\n",
      "        [ 6.0703e-01,  6.3814e-06,  2.1063e-02,  4.0552e-03,  2.2015e-03,\n",
      "          2.1727e-01,  8.3566e-02,  2.6629e-02,  2.5734e-03,  3.5602e-02],\n",
      "        [ 1.2893e-04,  4.0376e-06,  9.9453e-01,  4.2953e-03,  9.1928e-09,\n",
      "          8.1430e-08,  3.8278e-08,  4.0512e-05,  9.8672e-04,  1.0231e-05],\n",
      "        [ 1.4529e-05,  1.4257e-07,  6.2881e-06,  4.2558e-04,  3.9432e-05,\n",
      "          9.8636e-01,  4.7378e-04,  1.0831e-06,  9.8955e-03,  2.7863e-03],\n",
      "        [ 4.2991e-09,  5.9704e-06,  3.2174e-07,  3.2537e-07,  9.9855e-01,\n",
      "          3.8475e-07,  9.4504e-07,  3.5744e-06,  3.6506e-06,  1.4304e-03],\n",
      "        [ 6.5890e-05,  2.9205e-06,  3.3218e-05,  2.5547e-04,  1.0131e-08,\n",
      "          5.3434e-06,  4.4476e-10,  9.9893e-01,  3.3346e-06,  7.0156e-04],\n",
      "        [ 1.4574e-05,  9.8616e-01,  1.8616e-04,  7.5230e-04,  1.0207e-02,\n",
      "          9.8806e-05,  2.9343e-04,  1.2725e-03,  6.3928e-04,  3.7453e-04],\n",
      "        [ 2.5902e-04,  3.7905e-03,  6.4220e-01,  9.0545e-02,  2.0989e-04,\n",
      "          2.2568e-04,  1.5682e-05,  2.5199e-01,  6.8923e-03,  3.8704e-03],\n",
      "        [ 9.2412e-03,  1.5303e-04,  1.0523e-03,  1.2822e-05,  3.9963e-02,\n",
      "          9.8448e-04,  9.4600e-01,  3.7729e-05,  1.9184e-03,  6.3982e-04],\n",
      "        [ 5.9863e-06,  1.0248e-09,  4.9201e-07,  2.0901e-03,  3.7485e-09,\n",
      "          9.9706e-01,  1.7421e-05,  6.1161e-08,  8.0585e-04,  2.1159e-05],\n",
      "        [ 1.0660e-01,  2.0861e-04,  2.6029e-03,  2.3386e-05,  5.9273e-03,\n",
      "          3.4081e-04,  8.8353e-01,  5.8256e-05,  5.8715e-04,  1.1631e-04],\n",
      "        [ 7.4659e-03,  1.3260e-02,  3.9823e-03,  6.7818e-05,  9.0907e-01,\n",
      "          1.2310e-04,  2.0159e-02,  7.4695e-03,  1.4214e-03,  3.6976e-02],\n",
      "        [ 3.6295e-05,  9.9448e-01,  9.0381e-04,  8.9444e-04,  1.8788e-04,\n",
      "          2.8146e-05,  7.8363e-05,  1.1783e-03,  2.1459e-03,  7.0754e-05],\n",
      "        [ 9.9905e-01,  7.8208e-12,  4.1614e-04,  7.3810e-07,  2.6453e-12,\n",
      "          4.9137e-05,  1.2145e-05,  7.6269e-07,  4.6603e-04,  3.3511e-06],\n",
      "        [ 7.6787e-07,  3.5998e-10,  3.8233e-07,  2.6575e-03,  7.9097e-10,\n",
      "          9.9717e-01,  1.5257e-05,  2.7377e-09,  1.5697e-04,  8.7026e-07],\n",
      "        [ 8.9768e-06,  9.9793e-01,  1.3926e-04,  9.1901e-05,  1.0392e-03,\n",
      "          2.0066e-06,  3.1748e-05,  6.4890e-04,  8.7322e-05,  2.4743e-05],\n",
      "        [ 2.7943e-06,  1.6925e-04,  5.9610e-05,  1.2424e-03,  3.3859e-08,\n",
      "          1.1309e-06,  7.5567e-11,  9.9782e-01,  1.0826e-05,  6.9252e-04],\n",
      "        [ 1.3664e-04,  2.3981e-07,  4.0179e-05,  5.1318e-08,  6.5074e-03,\n",
      "          6.1832e-05,  9.9313e-01,  1.9414e-08,  1.1066e-04,  9.7015e-06],\n",
      "        [ 7.9431e-04,  5.2783e-04,  3.6208e-04,  3.5069e-01,  5.3137e-05,\n",
      "          6.2632e-01,  6.5549e-04,  1.3880e-03,  1.3526e-02,  5.6815e-03],\n",
      "        [ 3.0887e-05,  2.8033e-06,  1.5453e-05,  2.1714e-07,  6.7551e-04,\n",
      "          1.0135e-04,  9.9883e-01,  2.5787e-09,  3.3829e-04,  8.7543e-07],\n",
      "        [ 9.9927e-01,  3.6280e-10,  3.9838e-05,  4.2887e-06,  6.9087e-11,\n",
      "          5.7215e-04,  7.2898e-05,  3.1411e-06,  3.2438e-05,  1.5584e-06],\n",
      "        [ 7.5091e-05,  1.7229e-07,  2.5711e-05,  1.9660e-08,  3.5193e-05,\n",
      "          6.4724e-06,  9.9966e-01,  2.0518e-10,  1.9267e-04,  8.4220e-08],\n",
      "        [ 2.6866e-04,  8.2557e-04,  8.1693e-04,  1.7481e-05,  2.8617e-04,\n",
      "          2.1144e-04,  9.9289e-01,  9.8518e-08,  4.6782e-03,  1.3579e-06],\n",
      "        [ 1.1913e-04,  2.1412e-04,  6.1683e-02,  2.0186e-02,  3.9767e-07,\n",
      "          2.0736e-04,  6.6989e-06,  4.2559e-04,  9.1685e-01,  3.0918e-04],\n",
      "        [ 1.0203e-04,  1.5141e-04,  8.4851e-05,  3.5149e-04,  8.1452e-03,\n",
      "          1.5375e-03,  2.1700e-05,  2.1012e-02,  7.0528e-03,  9.6154e-01],\n",
      "        [ 1.1142e-06,  8.6081e-06,  2.5401e-05,  1.6308e-04,  4.0330e-04,\n",
      "          7.6293e-05,  3.1545e-08,  4.2614e-02,  2.3943e-03,  9.5431e-01],\n",
      "        [ 5.6783e-08,  4.0236e-10,  6.9213e-08,  3.4415e-03,  6.3654e-11,\n",
      "          9.9598e-01,  6.9184e-08,  1.7777e-08,  5.7189e-04,  3.1845e-06],\n",
      "        [ 1.8870e-06,  1.3196e-07,  6.2475e-06,  1.3945e-02,  1.4993e-06,\n",
      "          9.7623e-01,  4.9659e-05,  5.9362e-07,  8.8646e-03,  9.0203e-04],\n",
      "        [ 9.9930e-01,  2.2940e-11,  4.7353e-05,  1.2730e-08,  2.9266e-10,\n",
      "          9.0087e-06,  1.7745e-04,  1.2928e-07,  4.5579e-04,  5.4752e-06],\n",
      "        [ 1.1504e-04,  9.8863e-01,  3.6264e-03,  3.2490e-04,  3.1501e-03,\n",
      "          6.3867e-06,  1.7574e-04,  3.2468e-03,  6.2503e-04,  1.0107e-04],\n",
      "        [ 9.9883e-01,  5.9437e-09,  1.0103e-03,  9.4451e-07,  1.5675e-08,\n",
      "          2.8511e-06,  1.3403e-04,  6.4755e-06,  1.5566e-05,  4.3045e-06],\n",
      "        [ 2.6815e-05,  9.9782e-01,  2.2776e-04,  1.0854e-04,  7.8108e-04,\n",
      "          1.0284e-05,  3.2119e-04,  2.9188e-04,  3.9255e-04,  2.1070e-05],\n",
      "        [ 1.0673e-03,  6.3203e-03,  1.4329e-02,  1.5337e-02,  4.4833e-05,\n",
      "          1.6770e-04,  1.2391e-06,  9.3901e-01,  2.2925e-03,  2.1428e-02],\n",
      "        [ 7.7997e-04,  3.5216e-03,  1.7512e-01,  2.4896e-02,  1.3536e-06,\n",
      "          1.0813e-05,  6.5484e-08,  7.8663e-01,  3.9373e-03,  5.1050e-03],\n",
      "        [ 3.7109e-04,  1.5478e-02,  1.8844e-03,  3.5312e-03,  4.8535e-05,\n",
      "          6.6621e-05,  7.2169e-07,  9.6950e-01,  6.0755e-04,  8.5094e-03],\n",
      "        [ 5.0132e-08,  3.7550e-05,  2.9050e-06,  6.0105e-06,  9.9315e-01,\n",
      "          9.4883e-07,  8.4993e-07,  1.0778e-04,  2.5467e-06,  6.6871e-03],\n",
      "        [ 1.4128e-06,  1.8993e-05,  8.2651e-05,  9.9715e-01,  1.0472e-08,\n",
      "          4.0807e-04,  7.1978e-10,  2.1698e-03,  3.2626e-05,  1.3953e-04],\n",
      "        [ 3.4802e-05,  1.5454e-03,  1.8425e-04,  6.5876e-06,  9.9404e-01,\n",
      "          7.5272e-06,  5.9583e-04,  9.5357e-04,  5.0697e-05,  2.5778e-03],\n",
      "        [ 8.5165e-01,  3.1966e-07,  1.8955e-02,  1.3890e-04,  2.0195e-06,\n",
      "          1.3728e-02,  1.0883e-01,  6.0767e-06,  6.6004e-03,  8.6144e-05],\n",
      "        [ 1.1916e-07,  5.4620e-10,  4.0347e-08,  4.5470e-04,  1.4533e-09,\n",
      "          9.9947e-01,  6.6705e-06,  1.2617e-09,  6.4163e-05,  5.4333e-07],\n",
      "        [ 5.4493e-02,  1.1301e-07,  1.2504e-03,  1.4966e-04,  5.3259e-06,\n",
      "          3.1074e-02,  3.7204e-02,  1.4608e-06,  8.7350e-01,  2.3178e-03],\n",
      "        [ 1.3067e-05,  1.0515e-05,  2.6381e-05,  2.2812e-04,  7.3072e-08,\n",
      "          2.0242e-06,  2.5412e-10,  9.9875e-01,  2.7264e-06,  9.6335e-04],\n",
      "        [ 2.8957e-06,  4.3161e-06,  2.0036e-05,  5.7220e-05,  2.9256e-09,\n",
      "          8.9002e-08,  6.8329e-12,  9.9962e-01,  1.4039e-06,  2.8932e-04],\n",
      "        [ 3.5309e-05,  6.4037e-06,  1.9215e-04,  3.2703e-05,  5.3277e-03,\n",
      "          3.2782e-04,  1.3417e-05,  1.4792e-03,  4.9907e-02,  9.4268e-01],\n",
      "        [ 6.8124e-04,  9.1324e-03,  9.8210e-01,  6.2753e-04,  1.7133e-04,\n",
      "          1.6773e-06,  4.7131e-04,  1.0751e-04,  6.6601e-03,  4.7492e-05],\n",
      "        [ 5.4736e-08,  1.0605e-07,  3.5812e-05,  9.9972e-01,  1.7128e-11,\n",
      "          2.3289e-04,  1.1770e-10,  7.0701e-06,  7.3015e-06,  5.8875e-07],\n",
      "        [ 9.9622e-01,  1.1149e-08,  2.6753e-04,  7.5068e-07,  1.4529e-07,\n",
      "          5.5382e-05,  3.2705e-03,  1.5541e-06,  1.6364e-04,  1.7389e-05],\n",
      "        [ 9.9781e-01,  1.3245e-07,  9.2736e-04,  8.7626e-07,  6.1656e-07,\n",
      "          4.0200e-06,  1.2170e-03,  1.2525e-05,  2.0477e-05,  1.1621e-05],\n",
      "        [ 4.1186e-06,  8.2573e-09,  6.4894e-06,  1.2614e-02,  3.7153e-09,\n",
      "          9.8360e-01,  1.7847e-05,  5.1037e-08,  3.7443e-03,  1.6119e-05],\n",
      "        [ 6.8597e-05,  8.5259e-04,  1.3767e-03,  1.0231e-03,  3.2813e-07,\n",
      "          3.4680e-06,  5.7156e-09,  9.9342e-01,  2.4779e-04,  3.0078e-03],\n",
      "        [ 6.3781e-05,  5.5965e-06,  1.8989e-05,  1.8168e-07,  1.4135e-02,\n",
      "          1.0863e-04,  9.8545e-01,  6.0808e-08,  2.0671e-04,  1.1113e-05],\n",
      "        [ 1.1533e-05,  1.3393e-02,  2.7034e-02,  1.6885e-01,  1.5306e-04,\n",
      "          1.3893e-04,  1.4824e-07,  7.5701e-01,  8.0189e-03,  2.5392e-02]], device='cuda:0')\n",
      "tensor([ 9,  1,  2,  9,  3,  0,  3,  2,  5,  4,  7,  8,  3,  0,\n",
      "         2,  5,  4,  7,  1,  2,  6,  5,  6,  4,  1,  0,  5,  1,\n",
      "         7,  6,  3,  6,  0,  6,  6,  8,  9,  9,  5,  5,  0,  1,\n",
      "         0,  1,  7,  7,  7,  4,  3,  4,  0,  5,  8,  7,  7,  9,\n",
      "         2,  3,  0,  0,  5,  7,  6,  7], device='cuda:0')\n",
      "tensor([ 9,  1,  2,  9,  3,  0,  3,  2,  5,  4,  7,  8,  3,  0,\n",
      "         2,  5,  4,  7,  1,  2,  6,  5,  6,  4,  1,  0,  5,  1,\n",
      "         7,  6,  5,  6,  0,  6,  6,  8,  9,  9,  5,  5,  0,  1,\n",
      "         0,  1,  7,  7,  7,  4,  3,  4,  0,  5,  8,  7,  7,  9,\n",
      "         2,  3,  0,  0,  5,  7,  6,  7], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "class classify_net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(classify_net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5,padding=(2,2))\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5,padding=(2,2))\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool(F.relu(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool(F.relu(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = classify_net().cuda()\n",
    "pkl_dir = \"/home/lrh/program/git/pytorch-example/mnist_cnn/pkls/mnist_init_300epoch.pkl\"\n",
    "net.load_state_dict(torch.load(pkl_dir))\n",
    "\n",
    "\n",
    "net.zero_grad()\n",
    "\n",
    "data = dset.MNIST(root=\"/home/lrh/dataset/mnist\",train = False,download=True,transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ]))\n",
    "dataloader = torch.utils.data.DataLoader(data,batch_size=64,shuffle=True,drop_last=True)\n",
    "\n",
    "for i,data in enumerate(dataloader,0):\n",
    "    images,labels = data\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    pred = net(images)\n",
    "    _,logits = torch.max(pred,1)\n",
    "    print pred\n",
    "    print labels\n",
    "    print logits\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
